{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a959a9d8-1fb0-48a4-b9e2-d48d27ace7ce",
      "metadata": {
        "scrolled": true,
        "id": "a959a9d8-1fb0-48a4-b9e2-d48d27ace7ce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    accuracy_score,\n",
        "    classification_report\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea4463d6-8b0b-4793-b73f-a63aec4c8198",
      "metadata": {
        "id": "ea4463d6-8b0b-4793-b73f-a63aec4c8198"
      },
      "source": [
        "# 1. Hyper-parameters & settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a5c1ea1a-90e5-4b35-8f08-cd0013e693b9",
      "metadata": {
        "id": "a5c1ea1a-90e5-4b35-8f08-cd0013e693b9"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE    = 32\n",
        "EPOCHS        = 50\n",
        "LR            = 1e-3\n",
        "MAX_LEN       = 1000\n",
        "DEVICE        = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Compartments shared between train & test\n",
        "LABEL_COLS = [\n",
        "    'Cell membrane',\n",
        "    'Cytoplasm',\n",
        "    'Endoplasmic reticulum',\n",
        "    'Golgi apparatus',\n",
        "    'Lysosome/Vacuole',\n",
        "    'Mitochondrion',\n",
        "    'Nucleus',\n",
        "    'Peroxisome',\n",
        "]\n",
        "\n",
        "# Amino‐acid → index mapping (0 will be the PAD token)\n",
        "AA_LIST   = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "AA_TO_IDX = {aa: i+1 for i, aa in enumerate(AA_LIST)}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bb499b-7dfa-4f78-8ca8-afd4647a3fa6",
      "metadata": {
        "id": "f1bb499b-7dfa-4f78-8ca8-afd4647a3fa6"
      },
      "source": [
        "# 2. Sequence encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "76c8887f-0a29-4408-ab52-30f633591f95",
      "metadata": {
        "id": "76c8887f-0a29-4408-ab52-30f633591f95"
      },
      "outputs": [],
      "source": [
        "def encode_seq(seq, max_len=MAX_LEN):\n",
        "    # truncate\n",
        "    seq = seq[:max_len]\n",
        "    # map to indices, unknown → 0\n",
        "    idxs = [AA_TO_IDX.get(residue, 0) for residue in seq]\n",
        "    # pad\n",
        "    if len(idxs) < max_len:\n",
        "        idxs.extend([0] * (max_len - len(idxs)))\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c7d6e77-84fa-457a-9447-bdd942f788f2",
      "metadata": {
        "id": "1c7d6e77-84fa-457a-9447-bdd942f788f2"
      },
      "source": [
        "# 3. Dataset & DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0db60645-3953-42d1-8e39-25a1b8e88657",
      "metadata": {
        "id": "0db60645-3953-42d1-8e39-25a1b8e88657"
      },
      "outputs": [],
      "source": [
        "class ProteinDataset(Dataset):\n",
        "    def __init__(self, df, label_cols, seq_col='Sequence'):\n",
        "        self.seqs   = df[seq_col].values\n",
        "        self.labels = df[label_cols].values.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = encode_seq(self.seqs[idx])\n",
        "        y = torch.tensor(self.labels[idx])\n",
        "        return x, y\n",
        "\n",
        "def collate_fn(batch):\n",
        "    seqs, labels = zip(*batch)\n",
        "    seqs_tensor  = torch.stack(seqs)\n",
        "    labels_tensor= torch.stack(labels)\n",
        "    return seqs_tensor, labels_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "997f87c8-ad8f-4716-acef-954e42acc072",
      "metadata": {
        "id": "997f87c8-ad8f-4716-acef-954e42acc072"
      },
      "source": [
        "# 4. Load CSVs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d0bc58e9-e771-4efc-aed2-cdfe24717bd0",
      "metadata": {
        "id": "d0bc58e9-e771-4efc-aed2-cdfe24717bd0"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('data/Swissprot_Train_Validation_dataset.csv')\n",
        "test_df  = pd.read_csv('data/hpa_testset.csv')\n",
        "\n",
        "# rename HPA 'fasta' → 'Sequence'\n",
        "test_df = test_df.rename(columns={'fasta':'Sequence'})\n",
        "\n",
        "# keep only the columns we care about\n",
        "train_df = train_df[['Sequence'] + LABEL_COLS]\n",
        "test_df  = test_df [['Sequence'] + LABEL_COLS]\n",
        "\n",
        "train_dataset = ProteinDataset(train_df, LABEL_COLS)\n",
        "test_dataset  = ProteinDataset(test_df,  LABEL_COLS)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,  collate_fn=collate_fn)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d16693-92e2-4f1b-b6c8-0b29dd8cfa52",
      "metadata": {
        "id": "55d16693-92e2-4f1b-b6c8-0b29dd8cfa52"
      },
      "source": [
        "# 5. Model, loss, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f6eb01ec-300c-4b5c-8b62-6e389610ee82",
      "metadata": {
        "id": "f6eb01ec-300c-4b5c-8b62-6e389610ee82"
      },
      "outputs": [],
      "source": [
        "class DeepLocModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size: int,\n",
        "                 num_classes: int,\n",
        "                 emb_dim: int = 20,\n",
        "                 seq_len: int = 1000,\n",
        "                 filter_sizes=(1,3,5,9,15,21),\n",
        "                 num_filters: int = 20,\n",
        "                 lstm_hidden: int = 256,\n",
        "                 attn_units: int = 256,\n",
        "                 dec_steps: int = 10):\n",
        "        super().__init__()\n",
        "        # 1) Embedding\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "\n",
        "        # 2) Motif‐detector convolutions\n",
        "        #   6 filter sizes × 20 each = 120 output channels\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(emb_dim, num_filters, k, padding=k//2)\n",
        "            for k in filter_sizes\n",
        "        ])\n",
        "        # another conv: 128 filters of size 3 over the 120‐dim map\n",
        "        self.conv2 = nn.Conv1d(num_filters * len(filter_sizes),\n",
        "                               128, kernel_size=3, padding=1)\n",
        "\n",
        "        # 3) Bidirectional LSTM encoder\n",
        "        self.encoder = nn.LSTM(input_size=128,\n",
        "                               hidden_size=lstm_hidden,\n",
        "                               num_layers=1,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=True)\n",
        "\n",
        "        # 4) Attentive decoder\n",
        "        #   LSTMCell with 512 hidden units, run for D=10 steps\n",
        "        self.dec_steps = dec_steps\n",
        "        dec_input_dim = lstm_hidden*2 + lstm_hidden*2  # h_L (512) + c_prev (512)\n",
        "        self.decoder = nn.LSTMCell(dec_input_dim, lstm_hidden*2)\n",
        "\n",
        "        # Attention FFN: W_e, W_d → 256 units, then v → scalar score\n",
        "        self.W_e = nn.Linear(lstm_hidden*2, attn_units, bias=False)\n",
        "        self.W_d = nn.Linear(lstm_hidden*2, attn_units, bias=False)\n",
        "        self.v   = nn.Linear(attn_units, 1, bias=False)\n",
        "\n",
        "        # learned initial context vector c0\n",
        "        self.c0 = nn.Parameter(torch.zeros(lstm_hidden*2))\n",
        "\n",
        "        # 5) Classification head\n",
        "        self.fc        = nn.Linear(lstm_hidden*2, lstm_hidden*2)\n",
        "        self.classifier= nn.Linear(lstm_hidden*2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len) of token indices\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Embedding + convs\n",
        "        emb = self.embedding(x)                   # (B, L, emb_dim)\n",
        "        emb = emb.transpose(1, 2)                 # → (B, emb_dim, L)\n",
        "        conv_outs = [F.relu(conv(emb)) for conv in self.convs]\n",
        "        h = torch.cat(conv_outs, dim=1)           # (B, 120, L)\n",
        "        h = F.relu(self.conv2(h))                 # (B, 128, L)\n",
        "\n",
        "        # Encode with Bi-LSTM\n",
        "        h = h.transpose(1, 2)                     # → (B, L, 128)\n",
        "        enc_out, (hn, cn) = self.encoder(h)\n",
        "        # final encoder hidden state h_L for decoder input\n",
        "        h_forward  = hn[-2]                       # (B, 256)\n",
        "        h_backward = hn[-1]                       # (B, 256)\n",
        "        h_L = torch.cat([h_forward, h_backward], dim=1)  # (B, 512)\n",
        "\n",
        "        # Attentive decoding for D steps\n",
        "        # init decoder hidden & cell to zeros\n",
        "        d_h = torch.zeros(batch_size, h_L.size(1), device=x.device)\n",
        "        d_c = torch.zeros_like(d_h)\n",
        "        # init context to learned c0\n",
        "        c_prev = self.c0.unsqueeze(0).expand(batch_size, -1)\n",
        "\n",
        "        for _ in range(self.dec_steps):\n",
        "            # input = [h_L; c_prev]\n",
        "            dec_in = torch.cat([h_L, c_prev], dim=1)\n",
        "            d_h, d_c = self.decoder(dec_in, (d_h, d_c))\n",
        "\n",
        "            # compute attention scores over time steps\n",
        "            # enc_out: (B, L, 512), d_h: (B, 512)\n",
        "            # W_e(enc_out) → (B, L, attn_units)\n",
        "            # W_d(d_h)    → (B, attn_units) → unsqueeze(1) → (B, 1, attn_units)\n",
        "            e = torch.tanh(\n",
        "                self.W_e(enc_out) +\n",
        "                self.W_d(d_h).unsqueeze(1)\n",
        "            )                                       # (B, L, attn_units)\n",
        "            scores = self.v(e).squeeze(-1)          # (B, L)\n",
        "            α = F.softmax(scores, dim=1)            # (B, L)\n",
        "\n",
        "            # context = weighted sum of encoder outputs\n",
        "            c_prev = torch.bmm(α.unsqueeze(1), enc_out).squeeze(1)  # (B, 512)\n",
        "\n",
        "        # final classification\n",
        "        out = F.relu(self.fc(c_prev))             # (B, 512)\n",
        "        logits = self.classifier(out)              # (B, num_classes)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "de4e3805-2650-4140-a76e-6b238cb65f33",
      "metadata": {
        "id": "de4e3805-2650-4140-a76e-6b238cb65f33"
      },
      "outputs": [],
      "source": [
        "model     = DeepLocModel(vocab_size=len(AA_TO_IDX)+1,\n",
        "                    num_classes=len(LABEL_COLS)).to(DEVICE)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9de6cc7-05c3-4963-9b71-ee5c0b55a579",
      "metadata": {
        "id": "d9de6cc7-05c3-4963-9b71-ee5c0b55a579"
      },
      "source": [
        "# 6. Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24130f64-16b0-42d3-8eed-3d84788ccdc3",
      "metadata": {
        "id": "24130f64-16b0-42d3-8eed-3d84788ccdc3"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for seqs, labels in train_loader:\n",
        "        seqs, labels = seqs.to(DEVICE), labels.to(DEVICE)\n",
        "        logits = model(seqs)                    # (B, num_classes)\n",
        "        loss   = criterion(logits, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * seqs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"[Epoch {epoch:2d}/{EPOCHS}] Train Loss: {epoch_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bd478c3-7ca6-4278-8eec-de1a5b335028",
      "metadata": {
        "id": "3bd478c3-7ca6-4278-8eec-de1a5b335028"
      },
      "source": [
        "# 7. Evaluation on HPA test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds  = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for seqs, labels in test_loader:\n",
        "        seqs = seqs.to(DEVICE)\n",
        "        logits = model(seqs)\n",
        "        probs  = torch.sigmoid(logits).cpu().numpy()\n",
        "        preds  = (probs > 0.5).astype(int)\n",
        "        all_preds.append(preds)\n",
        "        all_labels.append(labels.numpy())\n",
        "\n",
        "all_preds  = np.vstack(all_preds)\n",
        "all_labels = np.vstack(all_labels)"
      ],
      "metadata": {
        "id": "c4psC63828pD"
      },
      "id": "c4psC63828pD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary confusion matrices for each class"
      ],
      "metadata": {
        "id": "TmSoFP3K2_qI"
      },
      "id": "TmSoFP3K2_qI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb634fd-7cae-44dd-a1ad-fa6cb9cd9b83",
      "metadata": {
        "id": "3eb634fd-7cae-44dd-a1ad-fa6cb9cd9b83"
      },
      "outputs": [],
      "source": [
        "for i, cls in enumerate(LABEL_COLS):\n",
        "    cm = confusion_matrix(all_labels[:, i], all_preds[:, i], labels=[0, 1])\n",
        "    disp = ConfusionMatrixDisplay(cm, display_labels=[f'not {cls}', cls])\n",
        "    fig, ax = plt.subplots()\n",
        "    disp.plot(ax=ax)\n",
        "    ax.set_title(f'Confusion Matrix: {cls}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-class confusion matrix (exact‐match)"
      ],
      "metadata": {
        "id": "JQnd29SJ3EQk"
      },
      "id": "JQnd29SJ3EQk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert multi-label to single-label by picking the highest‐scoring class\n",
        "y_true_single = all_labels.argmax(axis=1)\n",
        "y_pred_single = all_preds.argmax(axis=1)\n",
        "cm_multi = confusion_matrix(y_true_single, y_pred_single)\n",
        "disp_multi = ConfusionMatrixDisplay(cm_multi, display_labels=LABEL_COLS)\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "disp_multi.plot(ax=ax, xticks_rotation=45)\n",
        "ax.set_title('Multi-class Confusion Matrix (Exact Match)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "coJWxrWT3G3C"
      },
      "id": "coJWxrWT3G3C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-label classification report"
      ],
      "metadata": {
        "id": "PKynCySE3L3q"
      },
      "id": "PKynCySE3L3q"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Multi-label Classification Report:\")\n",
        "print(classification_report(\n",
        "    all_labels, all_preds,\n",
        "    target_names=LABEL_COLS,\n",
        "    zero_division=0\n",
        "))"
      ],
      "metadata": {
        "id": "mV6K9ANM3NcW"
      },
      "id": "mV6K9ANM3NcW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exact‐match accuracy"
      ],
      "metadata": {
        "id": "qyyN4niV3PPg"
      },
      "id": "qyyN4niV3PPg"
    },
    {
      "cell_type": "code",
      "source": [
        "exact_match_acc = accuracy_score(y_true_single, y_pred_single)\n",
        "print(f\"Exact‐match Localization Accuracy: {exact_match_acc:.4f}\")"
      ],
      "metadata": {
        "id": "EAhlxaP03R30"
      },
      "id": "EAhlxaP03R30",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}